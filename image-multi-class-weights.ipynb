{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"%matplotlib inline\nimport matplotlib.pyplot as plt\n\nimport numpy as np\nimport pandas as pd","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import os\nfrom glob import glob\nfrom copy import copy\nfrom sklearn.model_selection import train_test_split\nfrom keras.preprocessing.image import ImageDataGenerator","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"18c41871453fa8a4ead2604f938b178701883af7"},"cell_type":"code","source":"random_seed = 0\nnp.random.seed(random_seed)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a85e72f50cc89d34f868fb2f3954dd8a01591eef"},"cell_type":"code","source":"!ls -lh ../input","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"21a4080a42381fd96230080bae354255282b5a10"},"cell_type":"code","source":"all_data = pd.read_csv('../input/train/train.csv')\nlist(all_data.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"64703d29f45e6d77bb28d435489f960fba4ec9ec"},"cell_type":"code","source":"pet_data = all_data.set_index('PetID')\nimage_data = []\n\nfor image in glob('../input/train_images/*.jpg'):\n    basename = os.path.basename(image)\n    pet_id, _ = basename.rsplit('-')\n    pet_row = pet_data.loc[pet_id].to_dict()\n    pet_row['ImageFilename'] = image\n    pet_row['ImageBasename'] = basename\n    image_data.append(pet_row)\n    \nimage_data = pd.DataFrame(image_data)\n\nimage_data.head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"image_data['AdoptionSpeed']= image_data['AdoptionSpeed'].astype(str)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"image_data = image_data.loc[image_data['Type'] == 1]\n#image_data_cat = image_data.loc[image_data['Type'] == 2]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"14ba9f9d079e24182cf51e8ba1eba00d5d86ca39"},"cell_type":"code","source":"len(image_data), len(pet_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3e1185d1c46cadb2e479302bd608b207e3883436"},"cell_type":"code","source":"y = image_data['AdoptionSpeed']\ntest_size = 0.2\nvalidation_size = 0.2\n\n# Split the training data off from leftover (i.e. validation and testing)\n# train_test_split(*arrays, **options)\n# random_state is the seed used by the random number generator\n# data is split in a stratified fashion, using this as the class labels\nX_train, X_leftover, y_train, y_leftover = train_test_split(\n    image_data, y, test_size=test_size, random_state=random_seed,\n    stratify=y.values # stratify to ensure equal distribution of classes\n)\n\n# Determine how much the leftover section should be split to test\ntest_split = test_size / (test_size + validation_size)\n\nX_validate, X_test, y_validate, y_test = train_test_split(\n    X_leftover, y_leftover, test_size=test_split, random_state=random_seed,\n    stratify=y_leftover.values # stratify to ensure equal distribution of classes\n)\n\nX_train.shape, X_validate.shape, X_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#X_train['AdoptionSpeed'].hist(bins=3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"79e70e70c6b7ccc5f052937fd841d192b4ffb3d3"},"cell_type":"code","source":"train_datagen = ImageDataGenerator(\n    rescale=1./255,\n    rotation_range=40,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True)\n\nval_datagen = ImageDataGenerator(rescale=1./255)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"89396d68e17b5b1f65c9135a94ad7883e8073c72"},"cell_type":"code","source":"image_data.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#from imblearn.keras import BalancedBatchGenerator\n#from imblearn.under_sampling import NearMiss\n#training_generator = BalancedBatchGenerator.flow_from_dataframe(\n#     X, y, sampler=NearMiss(), batch_size=10, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"BATCH_SIZE = 30","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5df1913c0210e2fa52de0e10fc3d2b6150c07b95"},"cell_type":"code","source":"# Generate batches of tensor image data with real-time data augmentation. \n# The data will be looped over (in batches).\n\n\n\ntrain_generator = train_datagen.flow_from_dataframe(\n    X_train.reset_index(), # Need to reset index due to bug in flow_from_dataframe\n    directory='../input/train_images/',\n    x_col='ImageBasename',\n    y_col='AdoptionSpeed',\n    target_size=(150, 150),\n    color_mode='rgb',\n    class_mode='categorical',\n    batch_size=BATCH_SIZE,\n)\n\nval_generator = val_datagen.flow_from_dataframe(\n    X_validate.reset_index(), # Need to reset index due to bug in flow_from_dataframe\n    directory='../input/train_images/',\n    x_col='ImageBasename',\n    y_col='AdoptionSpeed',\n    target_size=(150, 150),\n    color_mode='rgb',\n    class_mode='categorical',\n    batch_size= BATCH_SIZE,\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from collections import Counter\ncounter = Counter(train_generator.classes)                          \nmax_val = float(max(counter.values()))       \nclass_weights = {class_id : max_val/num_images for class_id, num_images in counter.items()}                     ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#X_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#train_datagen = ImageDataGenerator(\n#    rescale=1./255)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n#train_generator = train_datagen.flow_from_dataframe(\n#    X_train.reset_index(), # Need to reset index due to bug in flow_from_dataframe\n#    directory='../input/train_images/',\n#    x_col='ImageBasename',\n#    y_col='AdoptionSpeed',\n#    target_size=(150, 150),\n#    color_mode='rgb',\n#    class_mode='categorical',\n#    batch_size=20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"71aaf4c1c163258255bb5247aefee57f701e4d7f"},"cell_type":"code","source":"import os\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import Model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0fdca6f9a762397b5c59a7800e81bb9c2bceccf5"},"cell_type":"code","source":"!wget --no-check-certificate \\\n    https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5 \\\n    -O /tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6845e990b1c240a5d030242bab1a588b350cdc80"},"cell_type":"code","source":"from tensorflow.keras.applications.inception_v3 import InceptionV3\n\nlocal_weights_file = '/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\npre_trained_model = InceptionV3(\n    input_shape=(150, 150, 3), include_top=False, weights=None)\npre_trained_model.load_weights(local_weights_file)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0481c19b0d1b760bd5d27aa54f26ed51bd317611"},"cell_type":"code","source":"for layer in pre_trained_model.layers:\n  layer.trainable = False","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5ea0997d217ef23e3ab849764ac66ad4814facce"},"cell_type":"code","source":"last_layer = pre_trained_model.get_layer('mixed7')\nprint ('last layer output shape:', last_layer.output_shape)\nlast_output = last_layer.output","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# import regularizer\nfrom keras.regularizers import l1\n# instantiate regularizer\nreg = l1(0.001)\n\n# example of l1 norm on activity from a cnn layer\nfrom keras.layers import Conv2D\nfrom keras.regularizers import l1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras import regularizers\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1d59fa63f7184be87a7f14362398202eae3f2928"},"cell_type":"code","source":"from tensorflow.keras.optimizers import RMSprop\n\n# Flatten the output layer to 1 dimension\nx = layers.Flatten()(last_output)\n# Add a fully connected layer with 1,024 hidden units and ReLU activation\nx = layers.Dense(512, activation='relu', kernel_regularizer=regularizers.l2(0.01), \n                 activity_regularizer=l1(0.001))(x)\n# Add a dropout rate of 0.2\nx = layers.Dropout(0.5)(x)\n# Add a final sigmoid layer for classification\nx = layers.Dense(5, activation='softmax')(x)\n\n# Dropout is a a technique used to tackle Overfitting . \n# The Dropout method in keras.layers module takes in a \n# float between 0 and 1, which is the fraction of the \n# neurons to drop. \n\n# Configure and compile the model\nmodel = Model(pre_trained_model.input, x)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5dd67d25b0c17c660ef4981112dd17e95ec7d35e"},"cell_type":"code","source":"from tensorflow.keras.optimizers import SGD\n\nunfreeze = False\n\n# Unfreeze all models after \"mixed6\"\nfor layer in pre_trained_model.layers:\n  if unfreeze:\n    layer.trainable = True\n  if layer.name == 'mixed6':\n    unfreeze = True\n\n# As an optimizer, here we will use SGD \n# with a very low learning rate (0.00001)\nmodel.compile(loss='categorical_crossentropy',\n              optimizer=SGD(\n                  lr=0.0001, \n                  momentum=0.9),\n              metrics=['acc'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5501ab895e83da11a8f4b1da45cde93fa41971ab"},"cell_type":"code","source":"history = model.fit_generator(\n      train_generator,\n      steps_per_epoch=len(X_train)//BATCH_SIZE,\n      epochs=100,\n      validation_data=val_generator,\n      validation_steps=len(X_validate)//BATCH_SIZE,\n      workers=4,\n      class_weight=class_weights,\n      verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0fe48d5f5df9ed14dd47a74f8c4b221e2c69da5b"},"cell_type":"code","source":"%matplotlib inline\n\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\n\n# Retrieve a list of accuracy results on training and test data\n# sets for each training epoch\nacc = history.history['acc']\nval_acc = history.history['val_acc']\n\n# Retrieve a list of list results on training and test data\n# sets for each training epoch\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\n# Get number of epochs\nepochs = range(len(acc))\n\n# Plot training and validation accuracy per epoch\nplt.plot(epochs, acc)\nplt.plot(epochs, val_acc)\nplt.title('Training and validation accuracy')\n\nplt.figure()\n\n# Plot training and validation loss per epoch\nplt.plot(epochs, loss)\nplt.plot(epochs, val_loss)\nplt.title('Training and validation loss')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}