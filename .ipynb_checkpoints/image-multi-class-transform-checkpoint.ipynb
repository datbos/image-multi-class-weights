{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "from copy import copy\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "18c41871453fa8a4ead2604f938b178701883af7"
   },
   "outputs": [],
   "source": [
    "random_seed = 0\n",
    "np.random.seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a85e72f50cc89d34f868fb2f3954dd8a01591eef"
   },
   "outputs": [],
   "source": [
    "!ls -lh ../input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "21a4080a42381fd96230080bae354255282b5a10"
   },
   "outputs": [],
   "source": [
    "all_data = pd.read_csv('../input/train/train.csv')\n",
    "list(all_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0cab5bb648dac5ac034b5ce4091dafc787eceff8"
   },
   "outputs": [],
   "source": [
    "all_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "64703d29f45e6d77bb28d435489f960fba4ec9ec"
   },
   "outputs": [],
   "source": [
    "pet_data = all_data.set_index('PetID')\n",
    "image_data = []\n",
    "\n",
    "for image in glob('../input/train_images/*.jpg'):\n",
    "    basename = os.path.basename(image)\n",
    "    pet_id, _ = basename.rsplit('-')\n",
    "    pet_row = pet_data.loc[pet_id].to_dict()\n",
    "    pet_row['ImageFilename'] = image\n",
    "    pet_row['ImageBasename'] = basename\n",
    "    image_data.append(pet_row)\n",
    "\n",
    "# rsplit() method returns a list of strings after breaking the given string \n",
    "# from right side by the specified separator.\n",
    "#  DataFrame.loc - Access a group of rows and columns by label(s) not by index.\n",
    "#  DataFrame.to_dict - Convert the DataFrame to a dictionary\n",
    "\n",
    "image_data = pd.DataFrame(image_data)\n",
    "image_data['AdoptionSpeed']= image_data['AdoptionSpeed'].astype(str)\n",
    "image_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "14ba9f9d079e24182cf51e8ba1eba00d5d86ca39"
   },
   "outputs": [],
   "source": [
    "len(image_data), len(pet_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3e1185d1c46cadb2e479302bd608b207e3883436"
   },
   "outputs": [],
   "source": [
    "y = image_data['AdoptionSpeed']\n",
    "test_size = 0.2\n",
    "validation_size = 0.2\n",
    "\n",
    "# Split the training data off from leftover (i.e. validation and testing)\n",
    "# train_test_split(*arrays, **options)\n",
    "# random_state is the seed used by the random number generator\n",
    "# data is split in a stratified fashion, using this as the class labels\n",
    "X_train, X_leftover, y_train, y_leftover = train_test_split(\n",
    "    image_data, y, test_size=test_size, random_state=random_seed,\n",
    "    stratify=y.values # stratify to ensure equal distribution of classes\n",
    ")\n",
    "\n",
    "# Determine how much the leftover section should be split to test\n",
    "test_split = test_size / (test_size + validation_size)\n",
    "\n",
    "X_validate, X_test, y_validate, y_test = train_test_split(\n",
    "    X_leftover, y_leftover, test_size=test_split, random_state=random_seed,\n",
    "    stratify=y_leftover.values # stratify to ensure equal distribution of classes\n",
    ")\n",
    "\n",
    "X_train.shape, X_validate.shape, X_test.shape\n",
    "# X_train['ImageFilename']\n",
    "val = X_train.at[10,'ImageFilename']\n",
    "X_train['ImageFilename']\n",
    "print (X_train['ImageFilename'] [:10])\n",
    "print (val)\n",
    "#img = mpimg.imread(val)\n",
    "#plt.imshow(img)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1599a3a2463698d5184b1bd5a830b14f09483d1d"
   },
   "outputs": [],
   "source": [
    "train_fnames = os.listdir('../input/train_images/')\n",
    "# train_dog_fnames.sort()\n",
    "print (train_fnames[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "79e70e70c6b7ccc5f052937fd841d192b4ffb3d3"
   },
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    horizontal_flip=True,\n",
    "    zoom_range=0.2,\n",
    "    shear_range=0.2,\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "cca7dcb5ec7e2e00bb13c22c87ecf24037405d16"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "# Parameters for our graph; we'll output images in a 4x4 configuration\n",
    "nrows = 2\n",
    "ncols = 4\n",
    "\n",
    "# Index for iterating over images\n",
    "pic_index = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5ac3264ad53ade55ca9d924c8f6188e93ba37f6f"
   },
   "outputs": [],
   "source": [
    "# Set up matplotlib fig, and size it to fit 4x4 pics\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(ncols * 4, nrows * 4)\n",
    "\n",
    "pic_index += 8\n",
    "# next_cat_pix = [os.path.join('../input/train_images/', fname) \n",
    "#                 for fname in train_cat_fnames[pic_index-8:pic_index]]\n",
    "next_pix = [os.path.join('../input/train_images/', fname) \n",
    "                for fname in train_fnames[pic_index-8:pic_index]]\n",
    "\n",
    "for i, img_path in enumerate(next_pix):\n",
    "  # Set up subplot; subplot indices start at 1\n",
    "  sp = plt.subplot(nrows, ncols, i + 1)\n",
    "  sp.axis('Off') # Don't show axes (or gridlines)\n",
    "\n",
    "  img = mpimg.imread(img_path)\n",
    "  plt.imshow(img)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d626c953f334f062816d96416cf12cc7c6fd95b1"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "      rotation_range=40,\n",
    "      width_shift_range=0.2,\n",
    "      height_shift_range=0.2,\n",
    "      shear_range=0.2,\n",
    "      zoom_range=0.2,\n",
    "      horizontal_flip=True,\n",
    "      fill_mode='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2f19d5c92e0454e7e01a1cbafe1355a10062439d"
   },
   "outputs": [],
   "source": [
    "print (X_train['ImageFilename'][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e387a1feb5bbb6f028821805fbe309c1f801f107"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import array_to_img, img_to_array, load_img\n",
    "\n",
    "# img_path = os.path.join(train_cats_dir, train_cat_fnames[4])\n",
    "img_path = X_train['ImageFilename'][6094]\n",
    "img = load_img(img_path, target_size=(150, 150))  # this is a PIL image\n",
    "x = img_to_array(img)  # Numpy array with shape (150, 150, 3)\n",
    "x = x.reshape((1,) + x.shape)  # Numpy array with shape (1, 150, 150, 3)\n",
    "\n",
    "# The .flow() command below generates batches of randomly transformed images\n",
    "# It will loop indefinitely, so we need to `break` the loop at some point!\n",
    "i = 0\n",
    "for batch in datagen.flow(x, batch_size=1):\n",
    "  plt.figure(i)\n",
    "  imgplot = plt.imshow(array_to_img(batch[0]))\n",
    "  i += 1\n",
    "  if i % 5 == 0:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ce53dabdf54452512c6df41f595dbd575765e25f"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "24090ae6a9729f5b214b8b9fb6fa8f46db456870"
   },
   "outputs": [],
   "source": [
    "# Adding rescale, rotation_range, width_shift_range, height_shift_range,\n",
    "# shear_range, zoom_range, and horizontal flip to our ImageDataGenerator\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,)\n",
    "\n",
    "# Note that the validation data should not be augmented!\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Flow training images in batches of 32 using train_datagen generator\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    X_train.reset_index(), # Need to reset index due to bug in flow_from_dataframe\n",
    "    directory='../input/train_images/',\n",
    "    x_col='ImageBasename',\n",
    "    y_col='AdoptionSpeed',\n",
    "    target_size=(150, 150),\n",
    "    class_mode='categorical',\n",
    "    batch_size=BATCH_SIZE,\n",
    ")\n",
    "# Flow validation images in batches of 32 using test_datagen generator\n",
    "val_generator = test_datagen.flow_from_dataframe(\n",
    "    X_validate.reset_index(), # Need to reset index due to bug in flow_from_dataframe\n",
    "    directory='../input/train_images/',\n",
    "    x_col='ImageBasename',\n",
    "    y_col='AdoptionSpeed',\n",
    "    target_size=(150, 150),\n",
    "    class_mode='categorical',\n",
    "    batch_size=BATCH_SIZE,\n",
    ")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f7f171199b434e72db0a01943bed8bb3c3cbbf2a"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "# architecture stack 3 {convolution + relu + maxpooling} modules. \n",
    "# Convolutions operate on 3x3 windows and the maxpooling layers operate on 2x2 windows. \n",
    "# The first convolution extracts 16 filters, the following one extracts 32 filters, \n",
    "# and the last one extracts 64 filters.\n",
    "# This is a configuration that is widely used and known to work well for image \n",
    "# classification. Also, since we have relatively few training examples (1,000), \n",
    "# using just three convolutional modules keeps the model small, which lowers \n",
    "# the risk of overfitting.\n",
    "# The input feature map is 150x150x3: 150x150 for the image pixels, and 3 for\n",
    "# the three color channels: R, G, and B\n",
    "img_input = layers.Input(shape=(150, 150, 3))\n",
    "\n",
    "# First convolution extracts 16 filters that are 3x3\n",
    "# Convolution is followed by max-pooling layer with a 2x2 window\n",
    "x = layers.Conv2D(16, 3, activation='relu')(img_input)\n",
    "x = layers.MaxPooling2D(2)(x)\n",
    "\n",
    "# Second convolution extracts 32 filters that are 3x3\n",
    "# Convolution is followed by max-pooling layer with a 2x2 window\n",
    "x = layers.Conv2D(32, 3, activation='relu')(x)\n",
    "x = layers.MaxPooling2D(2)(x)\n",
    "\n",
    "# Third convolution extracts 64 filters that are 3x3\n",
    "# Convolution is followed by max-pooling layer with a 2x2 window\n",
    "x = layers.Convolution2D(64, 3, activation='relu')(x)\n",
    "x = layers.MaxPooling2D(2)(x)\n",
    "\n",
    "# Flatten feature map to a 1-dim tensor\n",
    "x = layers.Flatten()(x)\n",
    "\n",
    "# Create a fully connected layer with ReLU activation and 512 hidden units\n",
    "x = layers.Dense(512, activation='relu')(x)\n",
    "\n",
    "# Add a dropout rate of 0.5\n",
    "x = layers.Dropout(0.5)(x)\n",
    "\n",
    "# Create output layer with a single node and relu activation\n",
    "output = layers.Dense(5, activation='relu')(x)\n",
    "\n",
    "# Configure and compile the model\n",
    "model = Model(img_input, output)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=RMSprop(lr=0.0001), # optimizer='rmsprop'\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4a68655c254518cea4564dcda8d2bbb8e285961e"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "48ff84086fadf53ead2c8ebfc87dc8eb24546adf"
   },
   "outputs": [],
   "source": [
    "# TODO: Add batch size to train and validation\n",
    "history=model.fit_generator(\n",
    "     train_generator,\n",
    "     epochs=10,\n",
    "     steps_per_epoch=len(X_train)//BATCH_SIZE,\n",
    "     validation_data=val_generator,\n",
    "     validation_steps=len(X_validate)//BATCH_SIZE,\n",
    "    # TODO: Add class weight\n",
    "     workers=4,\n",
    "     use_multiprocessing=True,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "51b0960bd80ccb636bb0e78773114aac7bd26580"
   },
   "outputs": [],
   "source": [
    "# Retrieve a list of accuracy results on training and test data\n",
    "# sets for each training epoch\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "\n",
    "# Retrieve a list of list results on training and test data\n",
    "# sets for each training epoch\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "# Get number of epochs\n",
    "epochs = range(len(acc))\n",
    "\n",
    "# Plot training and validation accuracy per epoch\n",
    "plt.plot(epochs, acc)\n",
    "plt.plot(epochs, val_acc)\n",
    "plt.title('Training and validation accuracy')\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "# Plot training and validation loss per epoch\n",
    "plt.plot(epochs, loss)\n",
    "plt.plot(epochs, val_loss)\n",
    "plt.title('Training and validation loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3ead196e092d25e558bba5fdc64890530ae9c579"
   },
   "outputs": [],
   "source": [
    "# As you can see, we are overfitting like it's getting out of fashion. Our training accuracy\n",
    "# (in blue) gets close to 100% (!) while our validation accuracy (in green) stalls as 70%. \n",
    "# Our validation loss reaches its minimum after only five epochs.\n",
    "# Since we have a relatively small number of training examples (2000), overfitting should\n",
    "# be our number one concern. Overfitting happens when a model exposed to too few examples \n",
    "# learns patterns that do not generalize to new data, i.e. when the model starts using \n",
    "# irrelevant features for making predictions. For instance, if you, as a human, only see \n",
    "# three images of people who are lumberjacks, and three images of people who are sailors, \n",
    "# and among them the only person wearing a cap is a lumberjack, you might start thinking \n",
    "# that wearing a cap is a sign of being a lumberjack as opposed to a sailor. You would \n",
    "# then make a pretty lousy lumberjack/sailor classifier.\n",
    "\n",
    "# Overfitting is the central problem in machine learning: given that we are fitting the \n",
    "# parameters of our model to a given dataset, how can we make sure that the representations\n",
    "# learned by the model will be applicable to data never seen before? How do we avoid \n",
    "# learning things that are specific to the training data?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
